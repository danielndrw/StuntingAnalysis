# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W3z1Yc9VexWeY6B325qMllY8vnWMt54s
"""

import os
import json
import numpy as np
import pandas as pd
import streamlit as st

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, silhouette_score, calinski_harabasz_score
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
import joblib

import folium
from streamlit_folium import st_folium

st.set_page_config(page_title="Stunting ‚Äî Regression, Klasifikasi & Clustering", layout="wide")

# ======================
# Utils
# ======================
CENTROIDS = {
    "ACEH": (4.695, 96.749), "SUMATERA UTARA": (2.115, 99.545),
    "SUMATERA BARAT": (-0.739, 100.800), "RIAU": (0.293, 101.707),
    "KEPULAUAN RIAU": (0.917, 104.446), "JAMBI": (-1.610, 103.613),
    "SUMATERA SELATAN": (-3.319, 104.914), "BENGKULU": (-3.577, 102.346),
    "LAMPUNG": (-4.558, 105.406), "KEP. BANGKA BELITUNG": (-2.741, 106.440),
    "BANTEN": (-6.405, 106.064), "DKI JAKARTA": (-6.175, 106.827),
    "JAWA BARAT": (-6.889, 107.640), "JAWA TENGAH": (-7.150, 110.140),
    "D I YOGYAKARTA": (-7.795, 110.369), "JAWA TIMUR": (-7.536, 112.238),
    "BALI": (-8.341, 115.092), "NUSA TENGGARA BARAT": (-8.652, 117.361),
    "NUSA TENGGARA TIMUR": (-8.657, 121.079), "KALIMANTAN BARAT": (-0.132, 111.095),
    "KALIMANTAN TENGAH": (-1.681, 113.382), "KALIMANTAN SELATAN": (-3.092, 115.283),
    "KALIMANTAN TIMUR": (0.538, 116.419), "KALIMANTAN UTARA": (2.838, 117.388),
    "SULAWESI UTARA": (1.493, 124.840), "GORONTALO": (0.699, 122.446),
    "SULAWESI TENGAH": (-1.430, 121.445), "SULAWESI BARAT": (-2.844, 119.232),
    "SULAWESI SELATAN": (-3.668, 119.974), "SULAWESI TENGGARA": (-4.144, 122.174),
    "MALUKU": (-3.238, 130.145), "MALUKU UTARA": (1.570, 127.808),
    "PAPUA": (-4.269, 138.080), "PAPUA BARAT": (-1.336, 133.174),
    "PAPUA BARAT DAYA": (-0.876, 131.255), "PAPUA PEGUNUNGAN": (-4.095, 138.944),
    "PAPUA SELATAN": (-8.493, 140.401), "PAPUA TENGAH": (-3.360, 135.500),
}

def norm_name(s: str) -> str:
    s = str(s).upper().strip()
    s = s.replace("D. I.", "D I ").replace("DI YOGYAKARTA", "D I YOGYAKARTA")
    s = s.replace("KEPULAUAN BANGKA BELITUNG", "KEP. BANGKA BELITUNG")
    return s

def ensure_cols(df: pd.DataFrame, required: list):
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.error(f"Kolom wajib hilang: {missing}")
        st.stop()

def try_load_geojson(uploaded_file):
    if uploaded_file is None:
        return None, None
    try:
        gj = json.load(uploaded_file)
        # deteksi field nama di properties
        props = gj["features"][0]["properties"]
        name_field = None
        for k in props:
            if k.lower() in ["provinsi","name","province","prov_name"]:
                name_field = k; break
        if name_field is None:
            name_field = list(props.keys())[0]
        # normalisasi nama
        for ft in gj["features"]:
            ft["properties"]["prov_norm"] = norm_name(ft["properties"][name_field])
        return gj, "prov_norm"
    except Exception as e:
        st.warning(f"Gagal membaca GeoJSON: {e}")
        return None, None

def choropleth_from_df(df_map, category_col, score_col=None, geojson=None, geo_key="prov_norm"):
    """Warna provinsi sesuai kategori; fallback ke marker jika GeoJSON tidak ada."""
    m = folium.Map(location=[-2.5, 118.0], zoom_start=5, tiles="cartodbpositron")
    cat_palette = {
        "Sehat": "#2E8B57",
        "Tidak Sehat": "#D9534F",
        "Sejahtera (Stunting Rendah)": "#2E8B57",
        "Sedang": "#F0AD4E",
        "Rentan (Stunting Tinggi)": "#D9534F"
    }
    if geojson is not None:
        lookup = df_map.set_index(geo_key)[category_col].to_dict()
        def style_fn(feature):
            prov = feature["properties"].get(geo_key, "")
            color = cat_palette.get(lookup.get(prov, ""), "#BDBDBD")
            return {"fillColor": color, "color": "white", "weight": 1, "fillOpacity": 0.9}
        folium.GeoJson(
            data=geojson,
            name="Map",
            style_function=style_fn,
            tooltip=folium.features.GeoJsonTooltip(fields=[geo_key], aliases=["Provinsi:"])
        ).add_to(m)
    else:
        # fallback marker
        for _, r in df_map.iterrows():
            prov = r[geo_key]
            latlon = CENTROIDS.get(prov)
            if not latlon:
                continue
            color = cat_palette.get(r[category_col], "#888888")
            text_score = "" if (score_col is None or score_col not in r) else f"<br/>Skor: {r[score_col]:.2f}"
            html = f"<b>{r['Provinsi']}</b><br/>{category_col}: <b>{r[category_col]}</b>{text_score}"
            folium.CircleMarker(
                location=latlon, radius=8, color="white", weight=1,
                fill=True, fill_color=color, fill_opacity=0.9,
                tooltip=r['Provinsi'], popup=folium.Popup(html, max_width=280)
            ).add_to(m)
    return m

# ======================
# Sidebar
# ======================
st.sidebar.title("Navigasi")
page = st.sidebar.selectbox(
    "Pilih fitur:",
    ["1) Regression (Random Forest)", "2) Klasifikasi Sehat vs Tidak Sehat", "3) Clustering Stunting (K=3)"]
)

st.sidebar.markdown("---")
st.sidebar.caption("Upload data utama (CSV). Disarankan data hasil cleaning/normalisasi.")

uploaded_csv = st.sidebar.file_uploader("Upload CSV", type=["csv"])
geojson_file = st.sidebar.file_uploader("(Opsional) Upload GeoJSON provinsi", type=["geojson","json"])

if uploaded_csv is None:
    st.info("Silakan upload CSV terlebih dahulu.")
    st.stop()

df = pd.read_csv(uploaded_csv)
df['prov_norm'] = df['Provinsi'].map(norm_name) if 'Provinsi' in df.columns else None

geojson, geo_key = try_load_geojson(geojson_file)

# ======================
# Page 1: Regression
# ======================
if page.startswith("1"):
    st.title("üîÆ Regression ‚Äî Prediksi Stunting (Random Forest)")
    req_cols = [
        'IPM','Kemiskinan_Persen','Akses_Sanitasi','Akses_Air_Minum',
        'Pengangguran_Persen','Pengeluaran_Kapita','PDRB','Stunting_2023'
    ]
    ensure_cols(df, req_cols)

    X = df[['IPM','Kemiskinan_Persen','Akses_Sanitasi','Akses_Air_Minum',
            'Pengangguran_Persen','Pengeluaran_Kapita','PDRB']].copy()
    y = df['Stunting_2023'].copy()

    test_size = st.sidebar.slider("Test size", 0.1, 0.4, 0.2, 0.05)
    n_estimators = st.sidebar.slider("n_estimators", 50, 500, 200, 50)
    max_depth = st.sidebar.slider("max_depth", 3, 20, 6, 1)
    random_state = 42

    # Train-test split
    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size, random_state=random_state)

    # RF non-standardized
    rf = RandomForestRegressor(
        n_estimators=n_estimators, max_depth=max_depth,
        min_samples_split=3, min_samples_leaf=2, random_state=random_state
    )
    rf.fit(X_tr, y_tr)
    y_pred = rf.predict(X_te)

    r2 = r2_score(y_te, y_pred)
    mae = mean_absolute_error(y_te, y_pred)
    rmse = np.sqrt(mean_squared_error(y_te, y_pred))

    colm = st.columns(3)
    colm[0].metric("R¬≤ (Test)", f"{r2:.4f}")
    colm[1].metric("MAE (Test)", f"{mae:.2f}")
    colm[2].metric("RMSE (Test)", f"{rmse:.2f}")

    st.subheader("Feature Importance")
    fi = pd.DataFrame({"Feature": X.columns, "Importance": rf.feature_importances_}).sort_values("Importance", ascending=False)
    st.dataframe(fi, use_container_width=True)

    st.subheader("Form Prediksi")
    c1, c2, c3 = st.columns(3)
    with c1:
        ipm = st.number_input("IPM", value=float(np.round(X['IPM'].mean(),2)))
        kem = st.number_input("Kemiskinan (%)", value=float(np.round(X['Kemiskinan_Persen'].mean(),2)))
    with c2:
        san = st.number_input("Akses Sanitasi (%)", value=float(np.round(X['Akses_Sanitasi'].mean(),2)))
        air = st.number_input("Akses Air Minum (%)", value=float(np.round(X['Akses_Air_Minum'].mean(),2)))
    with c3:
        peng = st.number_input("Pengangguran (%)", value=float(np.round(X['Pengangguran_Persen'].mean(),2)))
        kapita = st.number_input("Pengeluaran/Kapita (ribu/tahun)", value=float(np.round(X['Pengeluaran_Kapita'].mean(),1)))
        pdrb = st.number_input("PDRB", value=float(np.round(X['PDRB'].mean(),1)))

    if st.button("Prediksi Stunting"):
        xin = pd.DataFrame([{
            "IPM": ipm, "Kemiskinan_Persen": kem, "Akses_Sanitasi": san,
            "Akses_Air_Minum": air, "Pengangguran_Persen": peng,
            "Pengeluaran_Kapita": kapita, "PDRB": pdrb
        }])
        yhat = rf.predict(xin)[0]
        st.success(f"üéØ Prediksi Stunting: **{yhat:.2f}%**")

    if st.download_button("üíæ Simpan Model RF (joblib)", data=joblib.dump(rf, None), file_name="stunting_rf_model.joblib"):
        st.caption("Model tersimpan.")

# ======================
# Page 2: Klasifikasi Sehat vs Tidak Sehat
# ======================
elif page.startswith("2"):
    st.title("üè• Klasifikasi Sehat vs Tidak Sehat (K-Means k=2) ‚Äî Peta Indonesia")

    req_cols = [
        'Provinsi','Akses_Sanitasi','Akses_Air_Minum','IPM',
        'Pengangguran_Persen','Kemiskinan_Persen','PDRB'
    ]
    ensure_cols(df, req_cols)

    use_robust = st.sidebar.checkbox("Gunakan RobustScaler (tahan outlier)", value=True)
    scaler = RobustScaler() if use_robust else StandardScaler()

    dfc = df[['Provinsi','Akses_Sanitasi','Akses_Air_Minum','IPM',
              'Pengangguran_Persen','Kemiskinan_Persen','PDRB']].dropna().copy()
    dfc['prov_norm'] = dfc['Provinsi'].map(norm_name)
    dfc['PDRB_log'] = np.log1p(dfc['PDRB'].clip(lower=0))
    feat = ['Akses_Sanitasi','Akses_Air_Minum','IPM','Pengangguran_Persen','Kemiskinan_Persen','PDRB_log']
    Xs = scaler.fit_transform(dfc[feat])

    kmeans = KMeans(n_clusters=2, random_state=42, n_init=100)
    dfc['Cluster'] = kmeans.fit_predict(Xs)

    # Skor komposit -> tentukan cluster sehat
    Z = (dfc[feat] - dfc[feat].mean()) / (dfc[feat].std(ddof=0) + 1e-9)
    skor = Z['IPM'] + Z['Akses_Sanitasi'] + Z['Akses_Air_Minum'] + Z['PDRB_log'] - Z['Kemiskinan_Persen'] - Z['Pengangguran_Persen']
    dfc['Skor_Sejahtera'] = skor
    healthy_cluster = dfc.groupby('Cluster')['Skor_Sejahtera'].mean().idxmax()
    dfc['Kategori'] = np.where(dfc['Cluster']==healthy_cluster, 'Sehat', 'Tidak Sehat')

    st.dataframe(dfc[['Provinsi','Kategori','Cluster','Skor_Sejahtera'] + feat].sort_values(['Kategori','Provinsi']), use_container_width=True)

    m = choropleth_from_df(dfc, category_col='Kategori', score_col='Skor_Sejahtera', geojson=geojson, geo_key='prov_norm' if geojson is not None else 'prov_norm')
    st_folium(m, width=None, height=560)

    sil = silhouette_score(Xs, dfc['Cluster'])
    ch  = calinski_harabasz_score(Xs, dfc['Cluster'])
    colm = st.columns(2)
    colm[0].metric("Silhouette", f"{sil:.3f}")
    colm[1].metric("Calinski‚ÄìHarabasz", f"{ch:.1f}")

    st.download_button("‚¨áÔ∏è Unduh Hasil (CSV)", dfc[['Provinsi','Kategori','Cluster','Skor_Sejahtera'] + feat].to_csv(index=False).encode('utf-8'), "klasifikasi_sehat.csv")

# ======================
# Page 3: Clustering Stunting (K=3)
# ======================
else:
    st.title("üçº Clustering Stunting (K=3) ‚Äî Peta Indonesia")

    req_cols = [
        'Provinsi','Stunting_2023','IPM','Kemiskinan_Persen','Pengangguran_Persen',
        'Akses_Sanitasi','Akses_Air_Minum','PDRB','Rata_Lama_Sekolah'
    ]
    ensure_cols(df, req_cols)

    use_robust = st.sidebar.checkbox("Gunakan RobustScaler (tahan outlier)", value=True)
    scaler = RobustScaler() if use_robust else StandardScaler()

    # Fitur klaster TANPA stunting
    feature_cols = ['IPM','Kemiskinan_Persen','Pengangguran_Persen','Akses_Sanitasi','Akses_Air_Minum','Rata_Lama_Sekolah','PDRB']
    dst = df[['Provinsi','Stunting_2023'] + feature_cols].dropna().copy()
    dst['prov_norm'] = dst['Provinsi'].map(norm_name)

    # PDRB log jika >0
    if (dst['PDRB'] > 0).all():
        dst['PDRB_log'] = np.log1p(dst['PDRB'])
        scale_cols = [c for c in feature_cols if c != 'PDRB'] + ['PDRB_log']
    else:
        scale_cols = feature_cols

    X_scaled = scaler.fit_transform(dst[scale_cols])

    # KMeans k=3
    kmeans = KMeans(n_clusters=3, random_state=42, n_init=50)
    dst['Cluster'] = kmeans.fit_predict(X_scaled)

    # Evaluasi
    sil = silhouette_score(X_scaled, dst['Cluster'])
    ch  = calinski_harabasz_score(X_scaled, dst['Cluster'])
    c1, c2 = st.columns(2)
    c1.metric("Silhouette", f"{sil:.3f}")
    c2.metric("Calinski‚ÄìHarabasz", f"{ch:.1f}")

    # Label kategori berdasar rata-rata stunting per cluster (rendah->tinggi)
    st_mean = dst.groupby('Cluster')['Stunting_2023'].mean().sort_values()
    order = list(st_mean.index)
    label_map = {order[0]: 'Sejahtera (Stunting Rendah)', order[1]: 'Sedang', order[2]: 'Rentan (Stunting Tinggi)'}
    dst['Kategori_Stunting'] = dst['Cluster'].map(label_map)

    st.dataframe(dst[['Provinsi','Stunting_2023','Kategori_Stunting'] + scale_cols].sort_values('Stunting_2023'), use_container_width=True)

    # Peta
    m = choropleth_from_df(dst.rename(columns={'Kategori_Stunting':'Kategori'}), category_col='Kategori', geojson=geojson, geo_key='prov_norm' if geojson is not None else 'prov_norm')
    st_folium(m, width=None, height=560)

    # Optional: PCA plot (ringkas)
    try:
        import plotly.express as px
        pca = PCA(n_components=2, random_state=42)
        p2 = pca.fit_transform(X_scaled)
        dst['PCA1'], dst['PCA2'] = p2[:,0], p2[:,1]
        fig = px.scatter(dst, x='PCA1', y='PCA2', color='Kategori_Stunting', hover_name='Provinsi',
                         color_discrete_map={'Sejahtera (Stunting Rendah)':'#2E8B57','Sedang':'#F0AD4E','Rentan (Stunting Tinggi)':'#D9534F'},
                         width=900, height=520)
        st.plotly_chart(fig, use_container_width=True)
    except Exception:
        pass

    st.download_button("‚¨áÔ∏è Unduh Hasil (CSV)", dst[['Provinsi','Stunting_2023','Kategori_Stunting'] + scale_cols].to_csv(index=False).encode('utf-8'), "cluster_stunting_k3.csv")